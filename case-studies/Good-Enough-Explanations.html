<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Good Enough Explanations - Shubhangi Gupta</title>
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
	<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
	<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
	<script src="https://use.fontawesome.com/releases/v5.0.8/js/all.js"></script>
	<link href="../style.css" rel="stylesheet">
	<style>
@import url('https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap');

/* REFINED MAUVE PALETTE */
:root {
	--primary: #3D3034;
	--accent: #A47997;
	--accent-light: #C4A4B7;
	--secondary: #6B5D5A;
	--rose-gold: #B76E79;
	--champagne: #E8D5C4;
	--taupe: #C9B8AB;
	--ivory: #FAF7F2;
	--background: #FAF7F2;
	--surface: #FFFFFF;
	--border: #E8DFD6;
}

body {
	font-family: 'DM Sans', -apple-system, sans-serif;
	color: var(--primary);
	background-color: var(--background);
	line-height: 1.8;
	font-weight: 400;
}

h1, h2, h3, h4, h5, h6 {
	font-family: 'Crimson Text', serif;
	font-weight: 600;
	color: var(--primary);
}

/* Progress Bar */
.progress-bar-container {
	position: fixed;
	top: 0;
	left: 0;
	width: 100%;
	height: 4px;
	background: var(--border);
	z-index: 9999;
}

.progress-bar {
	height: 4px;
	background: linear-gradient(90deg, var(--accent) 0%, var(--rose-gold) 100%);
	width: 0%;
	transition: width 0.1s ease;
}

/* Navigation */
.navbar {
	background-color: var(--surface) !important;
	border-bottom: 2px solid var(--border);
	padding: 1.25rem 2rem;
}

.navbar-nav li {
	padding-right: 2rem;
	letter-spacing: 0.2px;
}

.nav-link {
	color: var(--secondary) !important;
	font-weight: 500;
	font-size: 0.95rem;
	transition: color 0.2s;
}

.nav-link:hover {
	color: var(--accent) !important;
}

#mylogo {
	width: 6.5rem;
}

.case-study-header {
	background: var(--surface);
	padding: 3rem 1rem 2rem 1rem;
	margin-bottom: 0;
	border-bottom: 1px solid var(--border);
}

.case-study-header .container {
	max-width: 800px;
	margin: 0 auto;
	padding: 0;
}

.case-study-header h2 {
	font-size: 2rem;
	font-weight: 600;
	color: var(--primary);
	margin-bottom: 0.5rem;
	font-family: 'Crimson Text', serif;
}

.case-study-header p {
	font-size: 1.05rem;
	color: var(--secondary);
	font-weight: 400;
	margin-bottom: 0;
}

.project-meta {
	display: flex;
	gap: 1.25rem;
	margin-top: 1.25rem;
	flex-wrap: wrap;
	font-size: 1.05rem;
}

.meta-item {
	color: var(--secondary);
}

.meta-item strong {
	color: var(--accent);
	font-weight: 600;
}

.content-wrapper {
	max-width: 800px;
	margin: 0 auto;
	padding: 3rem 1rem;
}

.at-a-glance {
	background: var(--surface);
	border-left: 4px solid var(--accent);
	padding: 2.5rem;
	margin: 3rem 0;
	border-radius: 0 12px 12px 0;
	box-shadow: 0 2px 12px rgba(164, 121, 151, 0.08);
	border: 1px solid var(--border);
	border-left: 4px solid var(--accent);
}

.at-a-glance h6 {
	font-family: 'DM Sans', sans-serif;
	text-transform: uppercase;
	letter-spacing: 0.15em;
	font-size: 0.7rem;
	font-weight: 700;
	color: var(--accent);
	margin-bottom: 1.5rem;
}

.at-a-glance p {
	margin-bottom: 1.25rem;
	color: var(--primary);
	font-size: 1.05rem;
	line-height: 1.8;
}

.at-a-glance p:last-child {
	margin-bottom: 0;
}

.at-a-glance strong {
	font-weight: 600;
	color: var(--accent);
}

.stats-row {
	display: grid;
	grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
	gap: 1rem;
	margin: 2rem 0;
}

.stat-box {
	background: var(--surface);
	border: 1px solid var(--border);
	border-radius: 8px;
	padding: 1rem 0.75rem;
	text-align: center;
}

.stat-number {
	font-size: 1.75rem;
	font-weight: 600;
	color: var(--accent);
	font-family: 'Crimson Text', serif;
	line-height: 1;
	margin-bottom: 0.35rem;
}

.stat-label {
	font-size: 0.75rem;
	color: var(--secondary);
	font-weight: 500;
}

.project-section h6 {
	font-size: 1.75rem;
	font-weight: 600;
	color: var(--primary);
	margin: 3.5rem 0 1.5rem 0;
	font-family: 'Crimson Text', serif;
}

.insight-box {
	background-color: var(--surface);
	border-radius: 12px;
	padding: 1.5rem 2rem;
	margin: 1.5rem 0;
	border: 2px solid var(--border);
	box-shadow: 0 2px 8px rgba(0,0,0,0.04);
}

.insight-box h6 {
	font-size: 1.2rem;
	font-weight: 600;
	color: var(--accent);
	margin: 1rem 0;
	font-family: 'Crimson Text', serif;
}

.insight-box p {
	color: var(--primary);
	margin-bottom: 0.75rem;
	line-height: 1.8;
}

.insight-box ul {
	margin-top: 1rem;
}

.insight-box li {
	margin-bottom: 0.75rem;
	color: var(--primary);
}

.quote-box {
	background: var(--surface);
	border-left: 4px solid var(--rose-gold);
	padding: 1.25rem 1.5rem;
	margin: 1.5rem 0;
	font-style: italic;
	color: var(--primary);
	border-radius: 0 8px 8px 0;
	font-size: 0.95rem;
	line-height: 1.7;
	border: 1px solid var(--border);
	border-left: 4px solid var(--rose-gold);
}

.quote-box .quote-author {
	margin-top: 0.75rem;
	font-style: normal;
	font-size: 0.8rem;
	color: var(--secondary);
	font-weight: 600;
}

.impact-highlight {
	background: var(--primary);
	color: white;
	padding: 3rem 2.75rem;
	border-radius: 12px;
	margin: 3rem 0;
	box-shadow: 0 8px 24px rgba(61, 48, 52, 0.3);
	position: relative;
	overflow: hidden;
}

.impact-highlight::before {
	content: '';
	position: absolute;
	top: 0;
	left: 0;
	right: 0;
	height: 4px;
	background: var(--rose-gold);
}

.impact-highlight h6 {
	color: white;
	font-weight: 600;
	font-size: 1.4rem;
	margin-bottom: 1.75rem;
	font-family: 'Crimson Text', serif;
}

.impact-highlight p,
.impact-highlight ul {
	color: rgba(255, 255, 255, 0.95);
}

.impact-highlight strong {
	font-weight: 700;
	color: var(--champagne);
}

p {
	margin-bottom: 1.5rem;
	color: var(--primary);
	font-size: 1.05rem;
}

ul {
	margin: 1.25rem 0;
}

li {
	margin-bottom: 0.875rem;
	color: var(--primary);
}

a {
	color: var(--accent);
	text-decoration: none;
	font-weight: 600;
	transition: color 0.2s;
}

a:hover {
	color: var(--accent-light);
	text-decoration: underline;
}

strong {
	font-weight: 600;
	color: var(--primary);
}

em {
	font-style: italic;
	font-family: 'Crimson Text', serif;
}

/* Footer */
.footer {
	background: var(--surface);
	border-top: 2px solid var(--border);
	padding: 3.5rem 0 2.5rem 0;
	text-align: center;
	margin-top: 5rem;
}

.footer p {
	color: var(--secondary);
	font-size: 0.9rem;
}

.social a {
	color: var(--accent);
	font-size: 1.75rem;
	margin: 0 1rem;
	transition: all 0.3s;
}

.social a:hover {
	color: var(--rose-gold);
	transform: scale(1.1);
}

.research-question {
	background-color: var(--ivory);
	padding: 2rem 2.25rem;
	border-radius: 8px;
	border-left: 4px solid var(--accent);
	margin-top: 2rem;
	margin-bottom: 2.5rem;
	border: 1px solid var(--border);
	border-left: 4px solid var(--accent);
	box-shadow: 0 2px 8px rgba(164, 121, 151, 0.06);
	font-size: 1.05rem;
	line-height: 1.8;
}

.research-question strong {
	color: var(--accent);
	font-weight: 600;
	display: block;
	font-size: 0.85rem;
	text-transform: uppercase;
	letter-spacing: 0.1em;
	margin-bottom: 0.75rem;
}

.research-question em {
	color: var(--primary);
	font-style: italic;
	font-size: 1.05rem;
}
</style>
</head>

<body>
	<!-- Progress Bar -->
	<div class="progress-bar-container">
		<div class="progress-bar" id="progressBar"></div>
	</div>

	<!-- Navigation -->
	<nav class="navbar navbar-expand-md navbar-light bg-white sticky-top">
		<div class="container">
			<a class="navbar-brand " href="../index.html"> <img id="mylogo" src="../img/logo.png"></a>

			<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive">
    			<span class="navbar-toggler-icon"></span>
  			</button>
  			<div class="collapse navbar-collapse" id="navbarResponsive">
  				<ul class="navbar-nav ml-auto">
  					<li class="nav-item ">
  						<a class="nav-link" href="../About.html"> About </a>
  					</li>
  					<li class="nav-item ">
  						<a class="nav-link" href="../RecentUpdatesMore.html"> News </a>
  					</li>

  					<li class="nav-item">
  						<a class="nav-link" href="../Research.html"> Projects </a>
  					</li>
  					<li class="nav-item">
  						<a class="nav-link" href="../Publications.html"> Publications </a>
  					</li>
  					<li class="nav-item">
  						<a class="nav-link" href="../Shubhangi_CV.pdf" target="_blank"> CV </a>
  					</li>
  				</ul>
  			</div>

	</div>
	</nav>

	<!-- Case Study Header -->
	<div class="case-study-header">
		<div class="container">
			<div class="row">
				<div class="col-12">
					<h2>Good Enough Explanations</h2>
					<p>Investigating Citizens' Civic AI Explanation and Transparency Needs </p>

					<div class="project-meta">
						<div class="meta-item"><strong>Timeline:</strong> 2021-2024</div>
						<div class="meta-item"><strong>Organization:</strong> Georgia Institute of Technology</div>
						<div class="meta-item"><strong>My Role:</strong> Lead Researcher</div>
						<div class="meta-item"><strong>Type:</strong> Generative Research</div>
					</div>
				</div>
			</div>
		</div>
	</div>

	<!-- Main Content -->
	<div class="content-wrapper">

		<!-- At a Glance -->
		<div class="at-a-glance" id="section-glance">
			<h6>At a Glance</h6>
			<p><strong>Challenge:</strong> The Explainable AI (XAI) research and design community lacks an understanding of what makes explanations of civic AI systems meaningful to diverse stakeholders affected by these tools.</p>
			<p><strong>Outcome:</strong> Developed the 'Good Enough Explanations' framework—a conceptual model defining four essential qualities of effective civic AI explanations.</p>
		</div>

		<!-- Stats -->
		<div class="stats-row">
			<div class="stat-box">
				<div class="stat-number">23</div>
				<div class="stat-label">Stakeholder Interviews</div>
			</div>
			<div class="stat-box">
				<div class="stat-number">7</div>
				<div class="stat-label">Stakeholder Groups</div>
			</div>
			<div class="stat-box">
				<div class="stat-number">3</div>
				<div class="stat-label">Publications</div>
			</div>
		</div>

		<!-- Research Challenge -->
		<div class="project-section" id="section-challenge">
			<h6>The Challenge</h6>
			<p>Civic AI systems are increasingly informing civic decision-making such as deploying police forces, allocating social services, or determining bail decisions. Yet these systems remain largely invisible and inaccessible to the publics who bear their consequences.</p>

			<p>While the XAI community has made significant advances in technical explainability (model cards, feature importance, etc.), there remain four critical gaps:</p>

			<ul>
				<li><strong>Not pluralistic:</strong> Failed to consider diverse values, knowledge systems, and lived experiences</li>
				<li><strong>Narrowly technical:</strong> Focused on algorithmic internals while ignoring surrounding social systems</li>
				<li><strong>One-time and passive:</strong> Treated explanation as a single transaction rather than ongoing process</li>
				<li><strong>Trust-focused:</strong> Aimed to build confidence rather than enable critical evaluation and action</li>
			</ul>

			<p>As such, this projects asks:</p>

			<div class="research-question"><strong>Research Question:</strong><em>What qualities underlie effective public explanations of civic predictive systems?</em></div>
		</div>

		<!-- My Role -->
		<div class="project-section" id="section-role">
			<h6>My Role</h6>
			<p>As lead researcher on this project, I was responsible for:</p>
			<ul>
				<li>Research conceptualization, design, and methodology development</li>
				<li>Participant recruitment across 7 diverse stakeholder groups</li>
				<li>Conducting all 23 semi-structured interviews</li>
				<li>Qualitative analysis (thematic analysis, affinity mapping)</li>
				<li>Framework synthesis</li>
				<li>Stakeholder presentations and dissemination</li>
			</ul>
		</div>

		<!-- Research Process -->
		<div class="project-section" id="section-process">
			<h6>Research Process</h6>

			<p><strong>Participants & Recruitment</strong></p>
			<p>I conducted semi-structured interviews with 23 participants across 7 stakeholder groups, all with direct experience thinking about, writing about, or acting on AI justice issues:</p>

			<div class="insight-box">
				<ul style="margin-bottom: 0;">
					<li>AI researchers and academics (n=7)</li>
					<li>AI activists and advocacy organizations (n=5)</li>
					<li>Journalists covering tech and AI (n=3)</li>
					<li>Community and neighborhood leaders (n=3)</li>
					<li>Civic society organizations (n=2)</li>
					<li>Policymakers (n=2)</li>
					<li>Legal scholars (n=1)</li>
				</ul>
			</div>

			<p style="margin-top: 1.5rem;"><strong>Interview Approach</strong></p>
			<p>Each 30-90 minute interview explored:</p>
			<ul>
				<li>What, if any, is the role of citizen-centered AI transparency in the design and deployment of just civic predictive tools? What is at stake and why? What arethe challenges? Why?</li>
				<li>What is needed to promote meaningful citizen-centered transparency? Is partial understanding enough? Why? Why not? What does democratic control over AI look like?</li>
				<li>Do you or your association think about AI use by cities? Why? Why not? Do you think there is a need to do that?</li>
				<li>What do you know about the use of AI for public safety in your neighborhood? What questions do you have? What forums exist to offer information on the use of AI by cities?</li>
			</ul>



			<p><strong>Analysis Methods</strong></p>
			<p>I used multiple qualitative analysis techniques:</p>
			<ul>
				<li><strong>Thematic analysis:</strong> Coded transcripts to identify patterns in explanation needs</li>
				<li><strong>Affinity mapping:</strong> Clustered insights across stakeholder groups</li>
				<li><strong>Literature integration:</strong> Connected findings to XAI, HCI, and STS scholarship</li>
				<li><strong>Framework synthesis:</strong> Distilled core qualities through iterative refinement</li>
			</ul>
		</div>

		<!-- Key Insights -->
		<div class="project-section" id="section-insights">
			<h6>Key Insights: The "Good Enough Explanations" Framework</h6>

			<p>Through this research, I developed the concept of <strong>"good enough explanations"</strong>—explanations that may not be complete or universal, but are good enough to support publics in critically engaging with AI systems. The framework identifies four essential qualities:</p>

			<div class="insight-box">
				<h6>1. Situated in Diverse Publics' Lives</h6>
				<p>Effective explanations ground technical concepts in the lived experiences, local knowledge, and existing concerns of specific communities. Rather than generic tutorials, they connect AI workings to familiar places, problems, and power structures.</p>
				<div class="quote-box">
					"What is needed in terms of transparency is always a function of what people are trying to accomplish...transparency needs to be molded in very specific ways so that people are being provided with particular pieces of information that are useful."
					<div class="quote-author">— Philosopher, Academic </div>
				</div>
			</div>

			<div class="insight-box">
				<h6>2. Explain Complex Socio-Technical Systems</h6>
				<p>Explanations must go beyond the "black box" algorithm to reveal the assemblages surrounding AI: who collects data and why, how historical biases become embedded, which institutions benefit, how predictions affect different communities.</p>
				<!-- <div class="quote-box">
					"The algorithm is just one piece. We need to understand the whole system—the data infrastructure, the power structures, the decision-making chain."
					<div class="quote-author">— AI researcher</div>
				</div> -->
				<div class="quote-box">
					"What data is being fed into the system?.. How does that impact the predictions?"
					<div class="quote-author">— Case worker, Innocence Project </div>
				</div>
				<div class="quote-box">
					"Who is impacted by these tools and how? What is the cost of incorrect predictions and who bears those costs"
					<div class="quote-author">— Data scientist, non-profit, focused on human rights violation</div>
				</div>
			</div>

			<div class="insight-box">
				<h6>3. Support Ongoing and Partial Processes</h6>
				<p>Understanding AI isn't a one-time event. Effective explanations enable continuous investigation, allow for partial knowledge, and create opportunities for collective sensemaking over time.</p>
				<div class="quote-box">
					"I think viewing them (predictive tools) as procedures that you can assess without knowing how the nuts and bolts of everything work, that is important."
					<div class="quote-author">— Philosopher, Academic </div>
				</div>
				<!-- <div class="quote-box">
					"Even partial understanding is valuable if it helps people ask the right questions and know where to push for more information."
					<div class="quote-author">— Policymaker</div>
				</div> -->
			</div>

			<div class="insight-box">
				<h6>4. Empower Public Action</h6>
				<p>Explanations should enable people to act—whether through advocacy, regulation, redesign, or resistance. The goal isn't just understanding, but supporting democratic oversight and intervention.</p>

				<div class="quote-box">
					"“I think there is a little bit of like false promise of transparency.. you absolutely have to have some of that in order to even start but that.. it’s sort of like the starting point rather than the final product” [P4]"
					<div class="quote-author">— Sociologist, Academic </div>
				</div>

			</div>
		</div>

		<!-- Impact & Outcomes -->
		<div class="project-section" id="section-impact">
			<h6>Impact & Outcomes</h6>

		<!-- 	<p><strong>Framework Adoption</strong></p>
			<ul>
				<li>Civic organizations used the framework to design community engagement strategies around AI systems</li>
				<li>AI advocacy groups referenced the framework in policy recommendations</li>
				<li>Educators adapted the framework for teaching AI ethics and transparency</li>
			</ul>
 -->
			<!-- <p><strong>Academic Contributions</strong></p> -->
			<ul>
				<li>Published at CHI 2023 (Late Breaking Works)</li>
				<li>Published at DIS 2023 (Doctoral Consortium)</li>
				<li>Cited in subsequent XAI and AI transparency literature</li>
			</ul>
<!-- 
			<p><strong>Real-World Application</strong></p>
			<p>This framework directly informed the design of participatory workshops and toolkits (see <a href="Participatory-AI-Toolkit.html">Participatory AI Transparency Toolkit</a> case study), demonstrating how generative research insights can translate into practical interventions.</p> -->
		</div>

		<!-- Reflections -->
		<div class="project-section" id="section-reflections">
			<h6>Reflections & Learnings</h6>

			<p><strong>What worked well:</strong></p>
			<ul>
				<li>Recruitment: For exploratory research, recruiting across diverse stakeholder groups revealed broad patterns that can be further developed in future work</li>
				<li>Methods: Semi-structured interviews allowed participants to surface their own priorities rather than responding to predetermined categories</li>
				<li>Synthesis: Connecting findings to multiple bodies of literature (XAI, HCI, STS) strengthened theoretical contributions</li>
			</ul>

			<p><strong>Future Work:</strong></p>
			<ul>
				<li>Include more end-users (citizens directly affected by civic AI) in addition to intermediaries</li>
				<li>Conduct follow-up interviews to validate the framework</li>
				<li>Explore how explanation needs differ across different types of civic AI (not just predictive policing) and stakeholder type. </li>
			</ul>

			<!-- <p><strong>Key takeaway for industry:</strong></p>
			<p>This research demonstrates that effective transparency isn't just about technical disclosure—it requires deep understanding of stakeholders' lived contexts, information needs, and goals. UX researchers play a critical role in bridging technical capabilities with human needs for AI systems.</p> -->
		</div>

		<!-- Related Publications -->
		<div class="project-section">
			<h6>Related Publications</h6>

			<p>1. Shubhangi Gupta and Yanni Alexander Loukissas. 2023. <a href="../Publications/Making Smart Cities Explainable.pdf" target="_blank"><i>Making Smart Cities Explainable: What XAI Can Learn from the "Ghost Map".</i></a> In Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems (CHI EA '23)</p>

			<p>2. Shubhangi Gupta. 2023. <a href="../Publications/DIS_2023_mapping_the_smart_city.pdf" target="_blank"><i>Mapping the Smart City: Participatory approaches to XAI.</i></a> Doctoral Consortium at Designing Interactive Systems (DIS) 2023.</p>

			<p>3. Shubhangi Gupta. 2024. <a href="../Publications/thesis.pdf" target="_blank"><i>Good Enough Explanations: How Can Local Publics Understand and Explain Civic Predictive Systems?</i></a> PhD Dissertation, Georgia Institute of Technology.</p>
		</div>

	</div>

	<!-- Footer -->
	<div class="container-fluid" style="padding-top: 8rem;">
		<div class="footer">
			<div class=" row text-center">
				<div class="col-12 social">
				<a href="https://twitter.com/_shubhangigupta" target="_blank"><i class="fab fa-twitter"></i></a>
				<a href="https://www.linkedin.com/in/shubhangigupta01/" target="_blank"><i class="fab fa-linkedin"></i></a>
				<a href='mailto:"shubhangi@gatech.edu"' target='_blank'><i class='fa fa-envelope'></i></i></a>
				</div>
			</div>
			<div>
				<p> Thanks for visiting! Let's stay connected. </p>
				<p>© Shubhangi Gupta</p>
		     </div>
		</div>
	</div>

	<script>
		// Progress bar functionality
		window.addEventListener('scroll', function() {
			var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
			var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
			var scrolled = (winScroll / height) * 100;
			document.getElementById("progressBar").style.width = scrolled + "%";
		});
	</script>

</body>
</html>
