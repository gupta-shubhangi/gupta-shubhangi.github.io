\section{What XAI Can Learn from the “Ghost Map"?}
  As I have already discussed, Human-Computer Interaction (HCI) and Machine Learning (ML) researchers have proposed several techniques for explaining and auditing algorithms and advancing algorithmic justice. However, more recently, XAI researchers have presented the importance of the \textit{form} of algorithmic explanations and its effect on the understanding of AI systems \cite{van2021effect}. Visualization experts and critical studies scholars have started employing visualizations as tools to explain and understand algorithms. I draw inspiration from this work to explore if and how \textit{mapping} can be employed as a technique to study and design good enough explanations. Below, I summarize some existing works that draw on visual techniques to explain algorithms and their limits. Next, I explore the opportunities presented by \textit{maps} by drawing on the work of Dr. John Snow, a physician-geographer, who traced the spread of cholera in the 1854 London epidemic through a map \cite{snow1856mode}, popularly termed the `Ghost Map' \cite{johnson2006ghost}. While these limits of XAI and affordances offered by maps to address them are not exhaustive, they are a good starting point to explore if and how maps can serve as useful tools to explain geo-spatial algorithms. 

\subsection{Visual explanations of AI}

Integrating XAI and visual design can make customer-facing explanation interfaces more usable and readable \cite{cheng2019explaining}. The effects of static and interactive visualization techniques of white box (where a model's inner working is shown) and black box (where input and output variables' relationships are shown) explanations on user comprehension have been investigated \cite{cheng2019explaining}. It was found that white-box interactive explanations were most effective in increasing user understanding but were worse than black-box explanations in increasing user confidence in their understanding. This may be a result of the complexity and cognitive overload of white-box explanations. An understanding of human cognition and decision-making capabilities is now being used to develop frameworks for explaining algorithms \cite{wang2019designing}. Researchers have also attempted to visualize ethical frameworks in order to make them more accessible to users who may not be familiar with ethical principles and terminologies \cite{sleigh2020visualizing}. However, more work is needed to design accessible white-box explanations of the design of algorithms.  

Share Lab has used data visualizations to represent several aspects of algorithms including algorithmic labor, invisible infrastructures that surround algorithms, and the social and political relations that inform the workings of tech companies \cite{sharelab}. Kate Crawford's work titled `Anatomy of AI' which displays several invisible aspects of labor, data, and environmental resources in relation to algorithms is another well-known example of visualizing algorithms \cite{anatomyofai}. These works draw great attention to the socio-political structures that surround the design of algorithms. However, they do not attempt to explain how the complexity of the world we live in is reduced to conform it to data practices.  
 
Interactive visual analytics are being used to help data scientists better understand their systems through the design of tools such as Prospector \cite{krause2016interacting}, Gamut \cite{hohman2019gamut}, Visual Auditor \cite{munechika2022visual}, and more. These tools visualize algorithms for controlled assessment and evaluation. More work is needed to incorporate real-life perspectives into algorithmic explanations.  

Data Comics have been presented as a means to better report HCI and statistical analysis research studies and are being explored as visualization techniques to communicate research processes and practices in accessible and engaging manners \cite{wang2020data}. Economist Julia Schneider and Artist Lena Kadriye Ziyal designed a comic series that explains what Artificial Intelligence is, its core properties, and the risks associated with its widespread deployment \cite{datacomic}. Explaining specific design decisions underlying the functioning of algorithms and their impact on the lives of its users still remains underexplored. 

These visual approaches to explaining AI are highly innovative and serve as great starting points for furthering research at the intersection of information design and XAI. However, the methodologies underlying these approaches to explain algorithms remain limited across four primary dimensions as I describe in my previous work \cite{gupta2023making}. I propose that these limitations may be well addressed by one popular visualization method for cities—\emph{maps}. The limits of existing explainable AI (XAI) approaches and the opportunities presented by maps to address those are listed below:    

\begin{enumerate}
    \item Accessibility: XAI methods can be incomprehensible for everyday users. On the other hand, maps are well understood—even treated with affection—by a broad spectrum of audiences. 
    \item Cultural reflexivity: XAI methods are commonly not representative of the social and political factors that shape algorithms and their designers whereas maps signify their own context of production through their visual languages that are culturally rooted.  
    \item Situatedness: XAI methods tend to be distant from situated real-world contexts and experiences of city inhabitants. Maps, however, draw on local knowledges of people and places in their making.  
    \item Design visibility: XAI methods focus on explaining the relation between input and output variables while disregarding how their representations of cities guide these relations. Maps reveal how the maker structured and segregated the city through its visual components. 
\end{enumerate}

This approach attempts to further the work of the scholars above and calls for the use of \emph{mapping} to produce grounded explanations of the inner life of cities in ways that are accessible, culturally reflexive, situated, and provide visibility into their design. I discuss how \textit{maps} can be effective in furthering such explanations and addressing the gaps in existing XAI research by drawing on the work of Dr. John Snow. I describe his work briefly in the section below.   

\subsection{The Ghost by John Snow: a brief description }
Dr. John Snow, a pioneer in social mapping, had been studying the periodic cholera epidemics in London since the 1830s. He hypothesized that cholera is water-borne and is caused by the ingestion of contaminated water in contrast to the then-popular belief that cholera is caused due to poisonous air. In the 1854 cholera breakout, Snow set out to identify and prove the cause of the disease. To do so, he mapped the fatalities and their proximity to various water pumps in the form of bars and dots. He noticed that the majority of deaths were taking place around the Broad Street water pump. However, there were some anomalies. A major brewery and a workhouse were largely unaffected by the disease. Upon talking to the people who lived and worked there, Snow found out that they both had their own individual wells for water consumption and the brewery workers majorly drank beer instead of water. He also observed that there were cases of outbreaks in areas distant from the Broad Street pump. Later, Snow found out that the people living there were still consuming the broad street pump water either because it was their place of work or school or because they enjoyed the taste of that water more. Snow presented his map to the authorities and citizens upon which the city agreed to remove the handle of the Broad Street pump to prevent people from consuming its water. Eventually, the epidemic ended. London has not seen a cholera breakout since \cite{snow1856mode}. What can I, along with fellow XAI researchers learn from this historical example, as we seek to explain the algorithms that govern ``smart cities?''

\input{chapter4_methods/sections/figures/ghostmap}

\subsection{Algorithmic Explainability: Limits and Opportunities of Mapping}

In the section below, I reflect on four strategies that maps have used to explain the complex inner lives of cities— accessibility, cultural reflexivity, situatedness, and design visibility. As a salient and well-known example of the explanatory power of maps, I will make use of John Snow's ``Ghost Map'' of London described above.  

\subsubsection{Accessibility}

Before John Snow's work on the Ghost Map revealed that Cholera is spread through drinking water, the London water distribution board was convinced that it was by something in the air, a miasma. They refused to believe the research presented by John Snow until he was able to supplement his research with a visual, easily understandable, and detailed representation of the precise spread of the epidemic. Snow gave spatial form to the General Registrar's data about cholera deaths. He converted one-dimensional data organized by date of death to two-dimensional data organized by proximity to water sources. This conveyed the cause-effect relationship between cholera infections and proximity to the Broad Street pump efficiently \cite{tufte1985visual} and clearly. The accessible nature of the map allowed many others to not only understand the map but to reproduce it \cite{johnson2006ghost}. It neatly captured the intricacies of the complex urban phenomenon that spread the disease and convinced the general public and authorities of its claim \cite{tufte1998visual, vaughan2018mapping}. According to Johnson Stevenson, the map helped make sense of a phenomenon (microorganisms invisible to the naked eye) that previously ``defied human understanding'' \cite{johnson2006ghost}. Ultimately, the map served as an excellent example of a user-friendly visual explanation. Popular XAI approaches are inaccessible to everyday users. Maps present an opportunity to explain algorithms in a comprehensible manner. 


\subsubsection{Reflexivity}

Visualizations bear the burden of being interpreted as a single objective reality of the world. However, this can be overcome with thoughtful consideration. John Snow, in his mapping and supplementary description, does not remove himself from his map. Rather, he carefully documents the possible errors that may have occurred in the data collection and presentation processes alongside the reasons for the possible errors. First, he clearly shows the contrast between deaths in houses near Broad Street pump and the brewery and workhouse nearby that remained unaffected. This leaves room to question the cause-effect relationship that Snow hypothesized. Second, in accompanying texts he lays out how some data he received from the registrar's office was missing house numbers and so could not be visualized \cite{tufte1998visual}. While this map itself is a reflexive artifact in the sense that it captures Snow's acknowledgment of his partial perspective through his mapping and descriptions, it also is an artifact that promotes reflexivity in the reader by challenging their stable perspectives. In its form, it communicates the time period it was created in and for what purposes, the region and scope of analysis, and what London looked like at the time.  


\subsubsection{Situatedness}

The data represented in the Ghost Map was informed by the everyday lives of the residents of Broad Street and the rest of London. To be able to design the map, Snow needed a fine-grained knowledge of the people of London. He conducted extensive interviews to understand people's movement patterns, sanitary conditions, water consumption practices, etc. He also collaborated with local people such as those who attended the sick. Even though the Ghost Map presents a bird's eye view so that the reader can observe patterns, it builds on situated knowledges of local experiences \cite{johnson2006ghost}. For example, Snow investigated why a brewery close to Broad Street was unaffected by the disease. He found out that it was primarily because the brewery workers mostly drank beer instead of water which saved them from the disease \cite{tufte1998visual}. Alongside considering the spatial distribution of the water sources, Snow also took into account the time it would take when walking along the turns of the city for a house member to reach various water sources. This further exemplifies the incorporation of situated elements, including temporality, that inform the design and analysis of the Ghost Map.  


\subsubsection{Design Visibility}

The Ghost Map followed and represented a clear hypothesis: Cholera spreads with the consumption of contaminated water. To analyze this hypothesis, Snow clearly displayed only two major components on the map— the water pumps in London and cholera-related deaths. He had a clear causal relationship in mind that he hoped to investigate and that was made clear to the reader \cite{tufte1998visual}. The clarity of the map also provided space for critical questions such as how the selection of time periods (aggregating cholera deaths over a week or a day) and boundaries drawn (deaths in a house or a block or another abstract segregation) affects our understanding of the spread of disease \cite{tufte1998visual}. Tufte critiqued John Snow's dot maps by arguing that visualizing deaths as dots gives little information about the population density of different areas. That is, deaths would likely be more in a densely populated area whether or not a water pump was the source of the disease. Had it not been for the map of Snow's analysis, Tufte would not have been able to critique and investigate the basis of the claim made by Snow.  Mapping how algorithms represent cities provides similar opportunities for critique. For example, when calculating the safety of a location, does the algorithm aggregate the crime rate without normalizing it by the population density of an area? If yes, what are the impacts of such design decisions?  


\subsection{What can explainable AI learn from the Ghost Map?}

In the sections above, I demonstrate the usefulness of \emph{mapping} as a technique to provide grounded explanations of spatial phenomenon in cities. I identified four strategies that conventional maps use to uncover the complex inner lives of cities.  These strategies, as I argue in my work \cite{gupta2023mapping}, can prove helpful when explaining geo-spatial algorithmic systems: \emph{accessibility, cultural reflexivity, situatedness, and design visibility}.  

Comprehending our urban environment by ``making public data public'' has been considered of utmost importance by many architects and city planners \cite{wurman1971making}. While I have focused on  the case of the influential Ghost Map by John Snow, many other cartographers, visual and information designers, and urban planners present similar noteworthy works that demonstrate the useful qualities of maps in explaining cities. Here are a few other references that XAI researchers might yet explore:   

\textit{Accessibility:} Popular XAI approaches are inaccessible to everyday users. Maps present an opportunity to explain algorithms in a comprehensible manner. In `The Image of the City' \cite{lynch1964image}, the proto-''city designer'' Kevin Lynch describes how he and his students at MIT identified five constitutive elements that city dwellers use to understand the places they live in: paths, edges, districts, nodes, and landmarks. The implication is that these five elements can form the core of ``legible'' city design and mapping.  With the longest print run of any book by MIT Press (more than eighty years), Lynch's work still serves as a useful tool for thinking about how the complex form of cities can be accessible. 

\textit{Reflexivity:} XAI methods do not explain the social-political contexts that shape algorithmic design. This limitation can be addressed by the calls for critical reflexivity in the mapping and representation of cities in fields such as `Critical Cartography' \cite{kim2015critical}. Such representations can challenge the status quo in a number of ways. Challenging western positivist cartographic techniques, some mapmakers are creating alternative forms of mapping that foreground indigenous forms of spatial knowledge \cite{pearce2008mapping}. Another similarly subversive map designed by Laura Kurgan and her collaborators called ``Million Dollar Blocks,'' draws critical attention to unequal practices of incarceration that specifically target Black neighborhoods in New York City (USA).  The map draws attention to a few low-income city blocks where millions of dollars are being invested—not for public health or education—but to remove the inhabitants and put them behind bars in the name of creating a safer city \cite{milliondollar}.  

\textit{Situatedness:} XAI methods tend to be distant from situated real-world contexts and experiences of city inhabitants. On the other hand, several artists and scholars have experimented with participatory mapping projects, that allow participants to make meaningful connections between authoritative data, such as census or censor readings, and their own local knowledge of the places they live in. One such example is the Atlanta Map Room Project \cite{maproom}, an expansion of the St.Louis Map Room \cite{stmaproom}, that brings together local community members to explore and represent the relationships between civic data and lived experiences. This grassroots mapping effort problematizes the “objective” and “stable” nature of big data and grounds data and its limits in contextual experiences of space.  

\textit{Design Visibility:} XAI approaches limit their scope to explaining the relation between input and output variables while disregarding how algorithms construct cities in their design. Decisions about what one chooses to represent on a map have a significant impact on who is affected by city design positively or negatively \cite{bosselmann1998representation}. Who is on the map or off the map affects who is included and who is not \cite{vertesi2008mind}. While maps construct reality through their representations, they also, through their very form, explain to us their constructed reality, leaving room for critiquing and improving said reality. 

Our goal here is take inspiration from the cultural history of visual design to design AI explanations. In this dissertation, I employ the above-mentioned affordances of maps to explain public safety algorithms to city inhabitants. I employ mapping as a technique to explore and explain how algorithms and the spatial aggregations they may create are grounded in the historical, economic, political, and social contexts of cities. 

Gupta et. al have shown how changes in spatial partitioning of cities for aggregation of data can have major effects on algorithmic results. For example, they demonstrate how the Gini index (a measure of spatial inequality) values change as one modifies the scale of calculation \cite{gupta2021spatial}. Given the impact of spatial partitioning on algorithmic outcomes and the need for algorithmic transparency in such cases, I conduct participatory mapping workshops with diverse groups to visualize algorithmic partitioning on maps, superimposing these distributions with other data layers that represent historical and contemporary segregations such as red-lining maps to ground the partitioning in historical politics. My hope is that this could help us evaluate if and how algorithms may reinforce or challenge existing city segregations. I describe these workshops in the section below. 

\subsection{Limits}

Even though I plan to use mapping to study and question spatial injustices, historically, mapping has also been used to propagate discriminatory agendas \cite{crampton2011mapping}. Maps may present distant and stable representations of reality which may favor the perceptions of one social group over another. However, with advancements in critical cartography and GIS, there are now new ways to question the ideologies and assumptions embedded in “objective” maps. Scholars are also exploring participatory mapping as a technique to problematize the positivist representations of cities and open up mapping for pluralistic exploration and critique \cite{lee2017collaborative}. I present mapping as an exploratory tool for advancing grounded XAI research while acknowledging its limitations.  