\textbf{Participatory Workshops. } One of the primary design decisions we made when designing effective explanations for publics was about how publics interact with the explanations. In my preliminary research involving interviews with communities, participants suggested the use of websites, videos, online lectures and panels, as potential modalities. These modalities, people suggested would allow the transfer of information to be easier to distribute, more efficient to consume, and easier to access. However, even though these forms already exist, publics remain unaware of the workings of civic AI systems. These forms are also not interactive. Lastly, they put us, as researchers, in the position of being ‘experts’ and having the ability to explain these systems to communities based on their needs. 

To address these limits, our work employed participatory workshops guided by a loose protocol to co-develop systemic explanations of AI. We designed for shared power in the development of explanations and actively considered everyone in the room an expert who brings in their local knowledges to help us collectively understand the workings and impacts of predictive systems. 


As we would expect to see in participatory workshops, participants led the conversation often building on each other's thoughts or challenging them. The participants brought in diverse local knowledges. Bringing those knowledges together resulted in the group being able to compare different neighborhoods in relation to the algorithmic effects they may feel. 


 Our prototcols were loose and participants at many instances brought in algorithmic components that may be more relevant or concerning to them. Our protocol allowed us to introduce explanation points (tiny pieces of information similar to data points) that the participants could them relate to in their local contexts. There were struggles.
 

 Personating required workshop coordinators to provide prompts that triggered the reflective process. These prompts were loosely followed but were essential to guide the participants to think about their prediction in relation to AI.  Personating AI predictions focused on the socio-technical workings of AI—what happens that allows AI to make predictions. We engaged in additional speculative exercises to consider how AI systems impact space—what happens after AI makes predictions