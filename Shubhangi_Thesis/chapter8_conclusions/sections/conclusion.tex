\begin{quote}
    ``Without awareness about these kinds of technologies, and without some level of understanding about how they're being used, there's no possibility for democratic oversight...Political change comes from getting individual people, regular citizens, involved in their local communities, and without an understanding of the existence of these tools, of who is making decisions about how to procure them and use them, how they're operating and so on, people can't mobilize around injustices that the tools help to perpetuate.'' Participant from Chapter 2 
\end{quote}

Today, even as AI systems rapidly invade every aspect of public life, everyday citizens remain unaware of what predictive tools exist, how they work, and what their impacts are. Without such an understanding citizens remain ill-equipped to inform, challenge, or protest the use of AI tools even as they are constantly subjected to their effects. They may not know why their job application was rejected, why they were not given a loan, why their child did not get into a school, or why they are seeing an seeing an increase in police presence in their neighborhood. This leaves citizens dis-empowered to demand just and equitable outcomes from civic decision-making organizations. Ultimately, it hinders citizen's democratic right to understand the systems that affect them, vocalize concerns, exercise meaningful participation, and hold civic organizations accountable.

\emph{How then can we support public understanding of the workings and effects of civic predictive systems?} In this dissertation, I conduct qualitative and participatory research to suggest one possible approach to address this question: designing systems for `Good enough explaining'. Good enough explanations, as I theorise in \Cref{ch2:gee}, may not be complete or universal, but are good enough to support diverse publics in critically engaging with the design, use, and regulation of AI. Such explanations (1) are \textit{situated} in the lives of diverse publics, (2) explain the complex and entangled socio-technical \textit{systems} that predictive tools interact with, (3) involve \textit{continuous and partial} processes, and lastly (4) empower publics to \textit{act} in ways that promote democratic deployment and regulation of predictive tools. 

Accepting the proposition of good enough explanations, one may ask: how do we then instill these qualities in explanations? To study this, I employ a `research through design' approach and examine how good enough explanations may come to be (see \cref{ch3:methods}). 

`Situated' explanation needs, as I demonstrate in \Cref{ch4:situated}, emerge from how publics relate to algorithmic contexts through (1) the predictive domain: the service domain that an AI model becomes a part of— in our case policing, (2) the prediction subject: the people or places that are subject to predictions—in our case neighborhoods, (3) the predictive backdrop: the local and global environment that surrounds predictive systems, and (4) the predictive tool: the tools and models that make predictions. These relations, I argue, must be considered in our attempt to design explanations for the evolving and situated needs of diverse publics. 

`Systemic' explanations of the socio-technical assemblages surrounding AI, that may address `situated' explanation needs, need not be developed by the XAI community isolation. Instead, as I demonstrate in \Cref{ch5:systemic}, these can be co-created with local publics who are positioned well to partially explain how algorithms interact with society to affect local contexts. Locals directly engage with components of AI systems outside of the ‘black box’ and can make known, amongst other aspects, the environments AI tools are deployed in, the cultures and norms they invade, and the lived experiences of the problems they attempt to address. XAI researchers can support the design of spaces that bring local publics together to help uncover nuanced networks underlying complex AI systems.

`Continuous and Partial' processes can support the development of `situated' and `systemic' explanations. AI systems can never be known in their entirety. As with all knowledge, they can only ever be known from specific standpoints and in specific settings \cite{harding2013rethinking}, i.e. they can only be known and explained \textit{partially}. Continuously evolving AI systems, therefore, demand continuous, long-term processes for the development of partial explanations. To moderate such processes, as I demonstrate in \Cref{ch6:discussion}, the XAI community will have to grapple with three primary design decisions: (1) designing explaining sites (2) designing explaining modalities, and (3) designing explaining interactions. These decisions will allow for the development of situated, systemic, continuous, and partial explanations. 

Lastly, `Actionable' explanations are surrounded by mechanisms that allow social groups to act. Unfortunately, I, as an independent researcher in academia was unable to study long term effects of the workshops on public action or promote direct public action towards redesigning, challenging, or discontinuing AI systems. However, my work highlights the ability of \textit{good enough explanations} to support publics in formulating actions, i.e. considering what public actions are necessary for the responsible deployment of civic AI tools and what could be their role in service of those actions; and formulating collectives that can come together to sustain processes of learning, debate, and action.  


\section{Context Considerations and Limits}

While I have identified considerations, constraints, and limits of this research in the previous chapters, here I provide three overarching points. 

First, this research is limited in its scope. I ground my investigation in the use of one public safety predictive tool— place based predictive policing. Researchers have studied this tool for over a decade which makes it a strong case study for investigating the development of effective explanations of this tool. Additionally, it allowed me to investigate geospatial workings of AI which are underexplored by the XAI community. Yet, many emerging and `hyped' tools such as AI Chatbots (ChatGPT) and Facial Recognition tools regularly came up in conversations. A more generalized conceptualization of public understanding of AI requires more work. 

Second, this research focuses on the use of civic AI in the United States (US) and the workshops are conducted in Atlanta, GA. As a developed nation in the Global North, my learnings from a study conducted in the US will not translate globally. More work is needed to understand the unique explanation needs of publics in developing countries that are also increasingly developing and deploying AI tools for public safety amongst other service domains. 

Third, the recruitment of interview and workshop participants was motivated by my goal to learn more about public explanations of civic AI from a wide range of stakeholders. I aimed to recruit participants with diverse experiences and relationships with predictive policing systems across their areas of participation and expertise. In this dissertation, I do not report on demographic information about the participants, because this dissertation serves as exploratory research that focused on social roles emerging around predictive technologies, rather than personal experiences. In later work, I plan to explore the importance of gender, race, age, and other demographic distinctions in the creation of explanations for civic AI. 

Ultimately, this dissertation serves as a starting point to investigate public explanations of civic AI systems and I propose concepts that can be useful for my fellow researchers to build on, nuance, or challenge. 

\section{Future Work}

Moving forward, this work can be developed in the following ways: (1) iterating workshops for the needs of specific social groups and developing a guidebook, (2) studying long term effects and needs, (3) developing a medium that organizes partial explanations over longer periods, and (4) taking steps to promote public action. 

\subsection{Workshops and guidebook} 

In the future, I plan to work more closely with fewer local organizations to understand their explanation needs and goals in contextual and grounded ways. As I have mentioned earlier, revealing algorithmic components can prompt the development of explanation needs and help formulate new collective understandings. A close collaboration will allow me to introduce novel and constantly evolving algorithmic components, navigate developments, and identify long-term effects and related actions.  

Through more nuanced collaborations and my work in this dissertation,  I plan to develop a guidebook (such as the Atlanta Community Engagement Playbook \cite{playbook}) for community organizers to aid them in conducting these workshops with the communities they work with. 

\subsection{Longer term engagement} 

Another dimension along which I want this work to progress is longer-term engagement with communities. I want to conduct follow-up workshops with social groups. Through this process, I also want to understand if and how these workshops are affecting their everyday lives. 

Gradually over these longer term enagagements, I would also be interested in inviting diverse groups together, such as through open call workshops, as they are more empowered and confident in their expertise to discuss, debate, and demand collective public action.

\subsection{Organizing partial explanations} 

In this work, I used `paper' to map our discussions. While the use of such a medium reduced the barrier to entry and invited more participation, it was also temporary. Often maps tore in transportation and their size made it difficult to look at multiple of them concurrently.

Following the lead of projects such as the Anti Eviction Mapping project \cite{evictionmap}, I plan to develop a digital, accessible, and widely shareable medium that can allow partial explanations to exist together on the same platform. It will also allow us to visualize these explanations alongside institutional data layers such as census data about race or income to understand how explanations for spaces differ with such socio-political characteristics. Such a representation was also requested by some of the workshop participants. 

\subsection{Promoting Action}

Lastly, I plan to offer workshops in ways that support publics to \textit{act}. I may do so by either offering the workshops in collaboration with existing civic systems that provide access to policymakers or city leaders or by directly including pathways to action as part of independent workshops. 

I also see an opportunity to center communities interaction with AI policy \cite{yang2024future}. We can do so by engaging in collective workshops with policy makers and community leaders to support each group in explaining these predictive tools in relation to themselves to the other group and formulating collective actions. This would be a longer-term undertaking and would require building robust relationships with multiple social groups.


\section{Positionality Statement}

I identify as a woman born and raised in India, a developing country in South East Asia. I have a background in Human-Computer Interaction. Growing up in a country where safety for women and girls has been a rising concern, I have always been attentive to technological advancements for safety. However, through my education and research, I have also been exposed to the harms these tools can cause even as they aim to promote public good. As a non-tech expert myself, I am attempting to understand what publics (like my own self) would need to know about these tools to carefully and responsibly identify the effects of these systems in relation to my communities and other marginalized peoples.  

During the time of the research, I have lived and worked in the United States as part of the Georgia Institute of Technology, a well-reputed university in South USA. My affiliation with the university gives me credibility and may have affected recruitment of stakeholders and participants for my dissertation. I have lived in the city in which the study was conducted for 6+ years which has helped me better relate to the local contexts and neighborhoods some participants in my research talk about. Ultimately, my analysis of the interviews and workshops I conduct is influenced by my personal and professional background and motivations as described above.  






