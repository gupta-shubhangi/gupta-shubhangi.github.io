In this section, I draw on my findings to present a framework of actors and their relations with predictive systems. I argue that public-centered explanation needs emerge out of these relations of feeling, knowing, and experiencing broader aspects of the predictive system such as the prediction domain, prediction subject, predictive tool, and predictive backdrop. Below, I explain these relations by drawing on workshops. Next, I discuss how this framework, as shown in figure 4.3, can be used to advance human-centered XAI research. 
 \input{chapter5_situated_explanations/figures/main_figure}

\subsection{Framework}
\subsubsection{Publics and Prediction Domain}

In this work, I identify the prediction domain as `public safety', or more specifically `policing'. People's beliefs, familiarity, and experiences with policing as well as other methods to promote public safety led them to ask about the goals of the predictive system, the impacts it may have, and who will bear the burden of harmful effects. They also considered the history of policing, the tools and standards used to measure effectiveness, and if and how they translate to predictive tools today. They drew contrasts with other policing methods in different places and in different times to investigate how predictive tools intervene in existing practices— do they reorient them or do they reinforce them?  

The starkest example of people feeling strongly towards `policing' was observed in Workshop 1 conducted with members of a police reform group. Their professional work put them in a unique position to witness the effects of policing. They possessed detailed knowledge of how police forces are incentivized to function and thereby questioned the position a predictive tool may take in this domain. Lastly, many of them identified as black people, born and raised in Atlanta, and had themselves experienced disparate treatment by residents and police alike in different neighborhoods. Ultimately their intricate and grounded knowledge of place-based public safety needs and conditions guided their investigation of the workings and effects of place-based predictive policing tools in Atlanta. Some recent work has also highlighted that people draw on their knowledge of police brutality along with their own experiences of racial profiling to demand oversight over the data that feeds the algorithmic models \cite{haque2024we}. 

\subsubsection{Publics and Prediction Subject}

In this chapter, I identify prediction subjects as `spaces or neighborhoods' in our cities that are categorized by predictive tools. People's perceptions and experiences of the places they live and work in led them to ask place-specific questions about predictive tools many times naming the areas such as `Buckhead' or `Old Fourth Ward' and asking about the quality of predictions made there.  They discussed the socio-political characteristics of neighborhoods such as mean income, or the resources present in a neighborhood such as healthcare, schooling, or grocery stores, and asked to know how these elements affect, and are affected by predictions. 

The prediction subject consists of not just the \textit{physical} spaces that are subject to predictions. The spaces include the lives of the people who live there, their histories, political leaning, relationships with each other, reputation, and so much more. Participants reflected on their relations with the people in their neighborhoods, contrasted them with other neighborhoods, and asked if and how communities that see homeless people or outsiders as threats report data and if that would affect the predictions. Predictions may not just be impacted by, but also impact people in different neighborhoods differently based on their relationship with policing. Participants asked what these disparate effects may be. 


\subsubsection{Publics and Predictive Backdrop}

In this work, I identify predictive backdrops as 'local and global' events surrounding the use of predictive tools. Several participants were motivated to participate due to their knowledge and experience of the booming AI industry and its harmful effects.  They wanted to make sense of the fast growth of AI they felt around them. Participants constantly drew on their knowledge of relevant policies and current events to ask questions about predictive tools. They focused on specific instances such as the Capitol attack on January 6th 2021, where over two thousand people violently invaded the United States Capitol Building in Washington, D.C., in support of then-U.S. president Donald Trump, two months after his defeat in the 2020 presidential election \cite{capitol}. They asked if and how predictive tools may help prevent such events. They asked about the effects of constitutional rights such as the Fourth Amendment that protects people against unreasonable searches and seizures and changes in laws such as decriminalizing marijuana, on the use of predictive tools. 

Participants also inquired about the need for cooperation and partnerships between different governmental and non-profit organizations required to deliver on the promises of safety that these tools made. They considered the reporting of other civic improvement data that they were more familiar with, such as the 311 data, and compared that with 911 data to ask about the effects of disparate reporting patterns and effects. 


\subsubsection{Publics and Predictive Tools }

For this paper, I identify prediction tool as `place-based predictive policing models' deployed to predict crime hotspots in a city.  While some groups were wary of the use of predicting tools in policing and wanted to know about how harms are being managed, others were cautiously optimistic and wanted to know how these tools can be effectively used to prevent crimes. The feelings participants had towards the predictive tool influenced their explanation needs and goals.  

Participants also asked questions about place-based predictive policing in relation to the broader world of AI including other tools used for public safety such as facial recognition systems or fingerprint scanners, as well as beyond public safety such as ‘ads’, ‘generative AI’, etc. Due to their more direct engagement with other automated tools, their questions were grounded in drawing contrasts with those tools. Oftentimes, participants' broader perception of AI (dystopian, privacy invading, optimistic, the next big thing), rather than their perception towards a specific tool, informed their questioning in the workshops. 

\subsection{Implications}

Exiting work on human-centered XAI has majorly focused on identifying user needs based on their technical knowledge and functional roles. The framework presented in this chapter advances existing work in two primary ways. One, I find that explanation needs emerge not just from user knowledges, but also from their feelings and experiences. Together I call knowing, feeling, and experiencing— \textit{relating}. Two, I demonstrate that publics \textit{relate} not just to the predictive tool, but also to the prediction subject, context, and backdrop, to seek explanations about the workings and effects of predictive systems. 

For us, \textit{knowledge} refers to information people gain through formal, practical, or social means; \textit{experiences} refer to direct interactions or lived experiences; and \textit{feelings} refer to the perceptions people may have. These \textit{relations} are entangled in many ways. For example, the knowledges and experiences of people inform their feelings and their feelings and experiences may inform the knowledge they seek and gain. Yet, the distinction between these three relations helps XAI researchers detangle them to an extent that they can be considered distinctly important, in their own right, as I design explanations for publics. Such a distinction would help researchers avoid reductive assumptions such as presuming that if a person is knowledgeable about AI, they may only need explanations for technical debugging. The person may seek explanations based on their lived experiences, such as justifying the increased police presence in their neighborhood, or to understand why people are worried about the use of AI in policing. 

The \textit{relations} defined above are not only with the predictive tool (the machine learning model that makes predictions about crime hotspots). In addition to  predictive technologies, publics relate to the prediction domain (policing), subject (space), and backdrop (local and global environments). Once again these elements are entangled. For example, policing practices may differ with spaces. The tools may not even be used in specific spaces. The backdrop may include historical policing practices in specific local spaces. This distinction can help XAI researchers consider how publics relate not just to the predictive tool alone, but also to these surrounding elements. People's knowledge of discriminatory police practices may lead them to ask about the protocols police forces follow when acting on a prediction. Their experience of space, such as observing gentrification, may lead to ask about the role of increased police presence in the same. These examples I provide above are inspired by the workshops. 

These relations with the predictive elements that I define in the paragraphs above are not exhaustive. Instead, they are a starting point into considering how human-centered explanations can account for the situated and grounded explanation needs of diverse publics. Some other researchers have also mentioned such relations with predictive elements. For example, Suresh et al. discuss personal knowledges of the milieu that aligns with my conceptualization of \textit{experiencing} predictive elements. I echo their findings and add nuance to their work through this framework by (1) providing empirical evidence by reflecting on real-world contexts of explaining and knowing predictive systems, and (2) detailing the relations with predictive elements in ways that can be useful for XAI researchers in identifying users' situated explanation needs. 





