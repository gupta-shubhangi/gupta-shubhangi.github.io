In this section, I report on the following questions and concepts that the stakeholders in this study considered essential for effective explanations of civic AI systems: (1) who receives and creates an explanation?; (2) what does an explanation explain?; (3) how is an explanation developed and shared?;  and (4) what are the goals and impacts of an explanation? Participants also discuss challenges faced by the research and activist community in designing effective explanations namely: (1) limited access to information about civic predictive tools, (2) lack of awareness, interest, or availability amongst the public to engage with predictive tools, and (3) lack of consensus on best ways to regulate tools and mitigate their harms. 

\subsection{Who receives and creates an explanation?}

For designing `public' centered explanations, participants highlight the importance of considering who comprises of the `public' [P4]. P3 talks about how those most at-risk may not be the ones involved in decision-making, and explains: 
\begin{quote}
  ``You'll often have people appealing to vaguely democratic justifications for police power, like the community supports this, right? ...but the people who support the bills are often not the people who will be subject to the police power.'' [P3]  
\end{quote}

It then becomes essential to carefully consider who the explanations are being designed for and therefore who is included in public conversation about predictive technologies. P4 reinforces this by speculating the following scenario: if we were to involve people from home-owners associations, we would self-select people who own homes and therefore are relatively richer [P4]. The choice of the `public' made by the XAI researchers then becomes essential and consequential to the just inclusion of communities in algorithmic oversight and governance.  

P2 describes how effective transparency is shaped by the needs and goals of publics in varied contexts: 

\begin{quote}
    ``What is needed in terms of transparency is always a function of what people are trying to accomplish...transparency needs to be molded in very specific ways so that people are being provided with particular pieces of information that are useful.'' [P2]
\end{quote}

Participants discuss in detail the diversity of explanation needs that various publics may have. While some people who want to audit the tools may want to know about the source code, data, and models used [P2]; others who are affected by the tool while being unaware of its existence may merely want to know about the presence of the tool along with its goals and effects [P13, P14, P17]. Civic organizations working to address issues of justice and inequality want to know how these tools may make their tasks harder [P20]. Police reform groups like policing diversion teams may ``\textit{want to know if these tools are going to make the police more or less likely to find themselves in situations where they are responding to diversion calls'}' [P2]. Management in large police departments \emph{``should be able to at least explain from one person to another the different elements that are being used''} [P5]. Other groups considered important stakeholders in need of explanations included: police advisory boards, neighborhood associations, city commissions, police officers, anti-police violence and anti-racial discrimination organizations, homeowners' associations, district attorneys, and public defenders. 


\subsection{What does an explanation explain?}

According to participants, explanations should make known the financial, historical, political, and social aspects of an AI system. They ask the following questions about place-based predictive policing systems:

\subsubsection{Financial} What is being spent on procuring these tools and where is the money coming from [P6, P7, P13]? How is taxpayer's money being used [P4]? What is the decision-making process that impacts the procurement of predictive tools for civic purposes [P11]? Vendor contracts signed by governmental agencies are opaque [P7] providing little transparency into how money is spent on these tools and who makes these decisions. Such gaps in knowledge, as stakeholders discuss, may prevent the public from participating in decisions about how taxpayer money is used.  

 \subsubsection{Historical} What are the origins of predictive technologies [P11, P23]? What existing systems and structures gave rise to these tools? How did we get here? [P23]. Knowledge about the historical grounding of these tools can help publics assess the harm caused by their predecessors and anticipate the possible impacts of the predictive tool in question [P11]. By understanding the effects of tools that came before predictive policing, and were deployed in a similar domain, such as body cams, we can evaluate how our current approaches are similar or different [P4].  

 \subsubsection{Socio-political} What are the motivations of the makers and buyers of these tools [P11, P9]? What are the priorities for the police departments [P3]? Are we policing sexual assault and homicide or sex work and decriminalized drug use [P3]? Technologists may try to find a problem that they think predictive tools can solve instead of thinking of ways to address problems that a community currently faces [P6]. It is essential to understand what community concerns are and if and how the predictive tools address said concerns. As P6 describes, predicting crime may not be a useful course of action in several cases:  

\begin{quote}
    ``At the end of the day, you're diagnosing a social problem and sending police as an answer to that problem when they can't really answer it... we need to find where to send extra social services, where to send employment resources, where to send, you know, other types of public resources, assistance to neighborhoods that are suffering from those problems.'' [P6] 
\end{quote}

Participants also raise questions about the impacts of predictive tools on diverse social groups: Who is impacted by these tools and how [P7]? What is the cost of incorrect predictions and who bears those costs [P7]? What are the civil rights and liberties cost? What are the racial justice costs [P6]? What are the discriminatory effects of using this tool vs not using it [P7]? How do these tools interact with other parts of the criminal justice system [P3]? Or other departments like housing or child welfare [P5]? How is its effectiveness/efficacy measured or evaluated [P7, P1]? Have there been studies to prove the public safety benefits of these tools [P6]? What are the safeguards in place for when the tool has negative impacts [P3]? Participants prioritize the need to learn about the impacts of public safety tools, including the validity and reliability of predictions, over the need to uncover the black box and understand how the model works [P6, P15]. They demand studies to evaluate the predictive tools and provide concrete evidence of their effectiveness and impacts on social groups [P6].  

 \subsubsection{Socio-technical} Participants discuss the need to understand the socio-technical elements that affect the working and use of predictive tools. Throughout the life cycle of the product, participants ask several questions:  

\emph{Existence of tools:} What systems are being used by different police departments [P3, P4]? When do the contracts end or are renewed [P13]? Basic descriptive information about what systems exist and are used by a city is essential for the public to engage with the use and regulation of the tools. 

\emph{Data Type and Limits:} What data is being fed into the system [P9]? Is the data specific to one's own community [P2]? How does that impact the predictions [P9]? What is over-represented and under-represented in data [P7]? Calls for service data may embody the assumptions of who and what looks suspicious to people who call 911. Arrest data are a product of targeted policing in black and brown neighborhoods. Learning about the data that a predictive system is trained on can support the public in identifying the limits of the tool and their potential impacts on their communities.  

\emph{Prediction Goal:} What kind of crimes is the tool predicting [P9]? P9 explains \emph{``it matters if crimes are found by police or are community reported''}. Since drug or intoxication crimes are officer-initiated crimes, the mere presence of police officers in a neighborhood can lead to an increase in the documentation of such crimes [P1]. This shifts the focus of police away from crimes such as assault and murder to petty crimes that are being decriminalized in several states.  

\emph{Action:} What are police instructed to do when they are in a crime hotspot [P1]? What does the successful use of a predictive tool look like [P5]? Are we collecting data about misidentifications, false arrests, police interactions, and pedestrian stops [P5, P6]? A predictive tool causes harm not through the act of making a prediction alone, but because of how the predictions change space and people in space. P7 discusses ShotSpotter, a tool that claims to identify gunshots and notifies police forces, \emph{``in the case of ShotSpotter, whether there was a gunshot or not, the police show up with the intent and state of mind of responding to gun violence and this is when really awful things can happen''} [P7]. Therefore, it is essential to assess the protocols followed by police forces as they interact with predictions [P6]. 

To summarize, for participants, meaningful public explanations provide informatiom about (1) finances related to funding predictive tools, (2) historical insights about the origins of predictive tools, (3) socio-political details including motivations and impacts of predictive tools, and (4) socio-technical details such as prediction goal, data use, and action protocols related to a predictive system. 

\subsection{How is an explanation developed and shared?}

Participants discussed the quality of methods needed for designing and delivering effective public explanations. P7 questioned the potential of one-off explanations: 
\begin{quote}
    ``I don't think there is a version where there's some educational thing and everybody in the community now understands this and it's like, okay, now go off and monitor your local police or whatever.'' [P7]  
\end{quote}

According to P7, such one-time explanations are ineffective in supporting public oversight over policing systems. Another feature discussed by participants relates to the extent of information explanations provide. P3 explains the importance of limited information and states:  

\begin{quote}
    ``I think viewing them (predictive tools) as procedures that you can assess without knowing how the nuts and bolts of everything work, that is important.'' [P3]
\end{quote}
 

Communicating the technicalities of how an AI system works may not be possible or may be unnecessary for the purposes and goals of local publics. As P6 states: \emph{``It (AI) can be a very intimidating language to try to enter...'' }[P6]. Therefore, according to our participants, explanations should limit and present themselves in ways that overcome the barriers of the language of AI, standing as a gatekeeper, preventing citizens from overseeing and assessing AI tools.  

P6 also emphasizes that not everyone needs to know all about the workings of predictive systems.  

\begin{quote}
    ``I don't think that there needs to be the same level of responsibility on each individual citizen to be able to sort of go toe to toe with the vendor or the or the, you know, police agency to say, you need to give me this, you need to give me that.'' [P6]
\end{quote}
	 

Diverse publics, then, may prefer different languages and focus points as they encounter explanations of AI systems.  


\subsection{What are the goals and impacts of an explanation?}

Participants emphasize that explanations are not an end in themselves. Instead, they serve as starting points, as stated by P4: \emph{``I think there is a little bit of like false promise of transparency.. you absolutely have to have some of that in order to even start but that.. it's sort of like the starting point rather than the final product''} [P4]. Explanations serve as precursors to other goals. For instance, a popular goal of transparency is to allow the public to hold tech makers and government officials accountable [P6]. But accountability doesn't simply flow from transparency [P4]. Mechanisms that support accountability need to be purposefully designed around transparency efforts.  

According to participants in this study, effective transparency via public explanations can serve many goals: 

 \subsubsection{Dialogue} Explanations can support productive and meaningful discussions amongst various stakeholders and help people share their experiences in relation to the tools [P7]. P7 stresses the need to be involved in discussions with community groups such as those most impacted by these tools alongside policymakers who need to be informed and knowledgeable enough to represent the needs of the communities they serve [P7].  

\subsubsection{Reflection and empowerment} People believe that predictive systems are more accurate than they actually are [P10]. Explanations can make these tools appear less magical [P11, P12] and support people in thinking of them merely as police allocation tools that may carry the same problems as traditional police allocation efforts. The explanations can help people reflect on what the tools are over-promising and how the tool impacts the practice of policing. Does it improve trust in police and promote community policing [P9]? A lack of understanding, P5 argues, would mean that one is placing their trust in the creators of these technologies who may have profit-oriented interests [P5].   

Explanations can also \emph{``help people see their own expertise as useful''} [P7] in assessing and regulating predictive tools in relation to their lives. They can transform citizens' thinking \emph{``I'm not an expert in technology. How could I possibly work to hold these people accountable''} [P2] to one where they see themselves as local experts who are able to effectively oversee tools that impact their communities and neighborhoods. As P6 states below, such local perspectives are essential for the responsible implementation of predictive tools.  

\begin{quote}
    ``...there is a lot of learning to do from community members and I think that lived experience of what's working in a community and what's not is essential to good policy and can give a ton of insight.'' [P6] 
\end{quote}

\subsubsection{Oversight and Assessment} Participants express the importance of public understanding in overseeing the responsible and equitable use of predictive tools. As P2 states below: 

\begin{quote}
    ``Without awareness about these kinds of technologies, and without some level of understanding about how they're being used, there's no possibility for democratic oversight...Political change comes from getting individual people, regular citizens, involved in their local communities, and without an understanding of the existence of these tools, of who is making decisions about how to use them, how they're operating and so on, people can't mobilize around injustices that the tools help to perpetuate.'' [P2]   
\end{quote} 

According to P2, an effective understanding of predictive tools creates possibilities for democratic oversight. Explanations can support citizens in helping evaluate the tools that affect their lives [P7].  Further, they can help protect citizens' civil liberties [P6]. They also introduce communities to some of the critiques about these tools [P7]. Some participants state that it is not essential for every citizen or user to know how a system works but that there is a need for audits of predictive systems by various domain experts [P3, P5]. 

\subsubsection{Regulation and change} Explanations can help people ask knowledgeable questions to tech vendors and policymakers [P6]. Explanations can support the public in thinking about what is needed to reduce the harms, reap the benefits of predictive tools [P6], and organizing against algorithmic injustices [P2]. Even the process of attempting to explain is helpful because as P5 states ``Sometimes the fact that there isn't an answer to the question is enough of an answer to that question to know that they shouldn't proceed'' [P5]. Ultimately, explanations can help create a ``place of conflict'' [P11], providing citizens with the vocabulary to understand the tools that affect their lives and demand change. 

\subsection{Challenges in creating explanations of civic AI}

Despite the progress made in the fields of XAI and AI transparency, the development and distribution of effective explanations remains challenging. Firstly, it is difficult access information about these tools. Secondly, many people may not be interested, available, or able to participate in discussions about the tools. And lastly, a lack of consensus on the best ways to regulate the tools can hinder collective organization efforts. I elaborate on these challenges below:

\subsubsection{Access to Information}

It is challenging to access information about predictive tools for several reasons. These tools are often developed by private organizations that are not obligated to share information [P2]. P5 elaborates on such lack of requirement to obligate: 

\begin{quote}
    ``It's a problem in our democracy and a problem for transparency because, as you have likely seen, one of the biggest issues, one of the most frequently cited exemptions when we are trying to understand anything about these systems tends to be the trade secrets. The reason that these algorithms aren't accessible or legible by the people using them is because the companies that are selling it don't want them to be accessible for anybody including the police departments.'' [P5] 
\end{quote}

Most information is protected from the public eye so as to either protect trade secrets from competitors [P5, P3] or keep people from taking advantage of transparency efforts to bypass the tool's security measures. Such opacity, justified by the need for security, not only prevents the public from holding police accountable but also reduces public trust and confidence in the institution of policing \cite{slupska2022secrecy}. Despite such restrictions, activists, journalists, and academics attempt to access the limited information available through Freedom of Information Act (FOIA) requests. Unfortunately, they remain unsuccessful in many cases as they either lack the legal resources to successfully submit requests and seek information, and/or the police departments fail to cooperate in good faith or respond in reasonable time [P3]. There also exists little incentive for police departments to share information about the use of these tools. P10 explains their lack of cooperation by saying \emph{``the less they share, the more protected they are''}. Even if one can identify some information about these systems, the information quickly becomes outdated [P4]. Such roadblocks can prevent people from continuing to take time out in pursuit of transparency [P5].   

\subsubsection{Ability to Learn}  

Not everyone is aware, available, interested, or able to learn more about the use of predictive tools in their cities. It may not be evident how civic predictive tools affect everyday citizens. And thus, citizens may not understand the need to think critically about these systems [P4]. As such, the development of meaningful explanations needs to be complemented by efforts to help people understand how these tools affect their lives [P4]. Several community experts confess that they would like to spend more time thinking about AI and its effects and are therefore interested in participating in events that provide them access to explanations [P20, P22, P23].  

Whether or not groups can learn about predictive tools and take necessary actions collectively also depends on if they have the social capital to organize themselves in ways that make them approachable [P3]. While there are XAI efforts that focus on policymakers or workers who directly interact with technologies, there is an alarming scarcity of work that engages with communities that are not organized in an official capacity simply due to logistical difficulties. Additionally, such tasks can just be overly demanding [P3]. People may also simply not be able to take out time to learn about predictive tools and participate in necessary actions. P8 explains: \emph{``If you're asking for just general volunteers it can be hard to find people that have time on their schedule, they really have to have a reason to be there...You have to find volunteers who are knowledgeable and committed and really are willing to keep the city honest''} [P8]. 

However, not everyone has the privilege of choosing not to participate. Those who are active and committed to the processes are generally the ones who are most affected by these tools and have the greatest to lose [P8]. This also implies that the burden of responsible deployment of technologies is put on communities of color and high poverty who have already had their trust destroyed by the police [P6].  

\subsubsection{Defining Action}
An essential component of just good enough explanations is their role in promoting action. However, it is challenging to act in unison when communities who are critical of predictive tools are unable to reach a consensus on the best ways to regulate these tools. P4 discusses at length the diversity of opinions and perspectives she came across during her empirical work with police departments, police reform groups, police abolitionists, and other policing-relevant social groups. She says \emph{``Different publics have different conceptions of what is public safety and what constitutes good use of taxpayer money''} [P4]. She elaborates on her comment with an example of conflicting perspectives and adds:  

\begin{quote}
   ``Abolitionist orgs would be like, we don't care about regulations and policies and like these bureaucratic things that only serve to further institutionalize the state surveillance ..whereas more reformist groups would say, what are the mechanisms for public comments and, how can we build in accountability on the front end and how can we do audits or ongoing evaluations or be able to even vote in an educated way by having some sort of algorithmic impact assessment on the front end. So that's where it becomes kind of difficult because it's like...yeah, there's all different kinds of things that you can do, but not everybody agrees with like what the right route is.'' [P4]  
\end{quote}

As P4 demonstrates, different social groups may not agree on what are the best ways to design, develop, and regulate predictive systems. Additionally, people who may be most affected by these tools may not even want to engage in such discussions. P22 explains that the communities he serves do not trust the police enough to get involved in the processes of improving or assessing policing tools. Their perspectives, then, may never be considered as we develop predictive tools. Therefore, even with good explanations and transparency, the public as a whole may not be able to collectively organize and demand change.  